{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNE+RNCKMsJ8Vti2NUpHGgq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsshreya/lsshreya.github.io/blob/master/object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0RGUJuK2Tmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "71db0c3f-5b8e-4519-ab0e-033bdbee13a2"
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.13.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.30.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (47.3.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faci3rtx2Z-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "38f98c46-6465-42b0-fb6b-156906507a92"
      },
      "source": [
        "!pip3 install imageai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imageai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n",
            "Installing collected packages: imageai\n",
            "Successfully installed imageai-2.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7meKOS_j2r5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "319dee1c-8ea6-49e6-c1a2-a0a4180ee13d"
      },
      "source": [
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-08 07:06:03--  https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200708T070603Z&X-Amz-Expires=300&X-Amz-Signature=3a0c47d04f935385d3626d1dbfa83b1679aca44802f5c6404b7132b4b319bccc&X-Amz-SignedHeaders=host&actor_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-08 07:06:03--  https://github-production-release-asset-2e65be.s3.amazonaws.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200708T070603Z&X-Amz-Expires=300&X-Amz-Signature=3a0c47d04f935385d3626d1dbfa83b1679aca44802f5c6404b7132b4b319bccc&X-Amz-SignedHeaders=host&actor_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.146.59\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.146.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248671664 (237M) [application/octet-stream]\n",
            "Saving to: ‘pretrained-yolov3.h5’\n",
            "\n",
            "pretrained-yolov3.h 100%[===================>] 237.15M  59.9MB/s    in 4.0s    \n",
            "\n",
            "2020-07-08 07:06:08 (59.4 MB/s) - ‘pretrained-yolov3.h5’ saved [248671664/248671664]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0DZBlHm23S9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "87a5aa0b-914d-4f85-89dc-65922af07881"
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spCdIZDT3FJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = DetectionModelTrainer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY7tiyVT3HOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.setModelTypeAsYOLOv3()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "641NZ9_s3I3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.setDataDirectory(data_directory=\"ring\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAuykxpM3ZVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "adf6bd0e-9273-4ec7-d166-4d0a8c057783"
      },
      "source": [
        "trainer.setTrainConfig(object_names_array=[\"ring\"], batch_size=4, num_experiments=20, train_from_pretrained_model=\"pretrained-yolov3.h5\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  ring/json/detection_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCirv19a2wSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2a7c8b7-b2d8-4903-88a0-51aa83b7e6c1"
      },
      "source": [
        "trainer.trainModel()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on: \t['ring']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Training with transfer learning from pretrained Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "160/160 [==============================] - 314s 2s/step - loss: 51.6982 - yolo_layer_1_loss: 6.6314 - yolo_layer_2_loss: 17.3126 - yolo_layer_3_loss: 27.7542 - val_loss: 18.3530 - val_yolo_layer_1_loss: 4.2943 - val_yolo_layer_2_loss: 5.7664 - val_yolo_layer_3_loss: 9.6944\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 220s 1s/step - loss: 12.5979 - yolo_layer_1_loss: 2.4006 - yolo_layer_2_loss: 4.1586 - yolo_layer_3_loss: 6.0387 - val_loss: 15.4603 - val_yolo_layer_1_loss: 2.3181 - val_yolo_layer_2_loss: 5.4004 - val_yolo_layer_3_loss: 5.3922\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 212s 1s/step - loss: 9.0157 - yolo_layer_1_loss: 1.6480 - yolo_layer_2_loss: 2.9647 - yolo_layer_3_loss: 4.4030 - val_loss: 5.9472 - val_yolo_layer_1_loss: 1.9878 - val_yolo_layer_2_loss: 3.0259 - val_yolo_layer_3_loss: 4.2345\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 227s 1s/step - loss: 8.2593 - yolo_layer_1_loss: 1.7075 - yolo_layer_2_loss: 2.8750 - yolo_layer_3_loss: 3.6768 - val_loss: 6.7990 - val_yolo_layer_1_loss: 1.5512 - val_yolo_layer_2_loss: 2.7630 - val_yolo_layer_3_loss: 3.6121\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 228s 1s/step - loss: 7.2872 - yolo_layer_1_loss: 1.4725 - yolo_layer_2_loss: 2.5437 - yolo_layer_3_loss: 3.2710 - val_loss: 7.2087 - val_yolo_layer_1_loss: 1.5840 - val_yolo_layer_2_loss: 2.2840 - val_yolo_layer_3_loss: 3.2282\n",
            "Epoch 6/20\n",
            "160/160 [==============================] - 225s 1s/step - loss: 6.2070 - yolo_layer_1_loss: 1.4580 - yolo_layer_2_loss: 2.1020 - yolo_layer_3_loss: 2.6470 - val_loss: 12.7779 - val_yolo_layer_1_loss: 2.0311 - val_yolo_layer_2_loss: 2.2927 - val_yolo_layer_3_loss: 3.6073\n",
            "Epoch 7/20\n",
            "160/160 [==============================] - 217s 1s/step - loss: 5.6843 - yolo_layer_1_loss: 1.1629 - yolo_layer_2_loss: 2.0084 - yolo_layer_3_loss: 2.5130 - val_loss: 13.6714 - val_yolo_layer_1_loss: 1.6513 - val_yolo_layer_2_loss: 2.6026 - val_yolo_layer_3_loss: 3.2343\n",
            "Epoch 8/20\n",
            "160/160 [==============================] - 228s 1s/step - loss: 6.0421 - yolo_layer_1_loss: 1.3484 - yolo_layer_2_loss: 2.1727 - yolo_layer_3_loss: 2.5210 - val_loss: 2.8849 - val_yolo_layer_1_loss: 1.3244 - val_yolo_layer_2_loss: 2.4332 - val_yolo_layer_3_loss: 2.9503\n",
            "Epoch 9/20\n",
            "160/160 [==============================] - 223s 1s/step - loss: 5.6923 - yolo_layer_1_loss: 1.2664 - yolo_layer_2_loss: 2.0591 - yolo_layer_3_loss: 2.3668 - val_loss: 7.1483 - val_yolo_layer_1_loss: 1.0214 - val_yolo_layer_2_loss: 2.1219 - val_yolo_layer_3_loss: 3.5253\n",
            "Epoch 10/20\n",
            "160/160 [==============================] - 213s 1s/step - loss: 4.3954 - yolo_layer_1_loss: 0.8082 - yolo_layer_2_loss: 1.6046 - yolo_layer_3_loss: 1.9826 - val_loss: 10.1070 - val_yolo_layer_1_loss: 1.0832 - val_yolo_layer_2_loss: 2.6449 - val_yolo_layer_3_loss: 2.8368\n",
            "Epoch 11/20\n",
            "160/160 [==============================] - 228s 1s/step - loss: 3.3953 - yolo_layer_1_loss: 0.7023 - yolo_layer_2_loss: 1.2034 - yolo_layer_3_loss: 1.4896 - val_loss: 10.7849 - val_yolo_layer_1_loss: 1.2206 - val_yolo_layer_2_loss: 2.0955 - val_yolo_layer_3_loss: 2.6427\n",
            "Epoch 12/20\n",
            "160/160 [==============================] - 218s 1s/step - loss: 3.0112 - yolo_layer_1_loss: 0.5555 - yolo_layer_2_loss: 1.0757 - yolo_layer_3_loss: 1.3800 - val_loss: 1.8045 - val_yolo_layer_1_loss: 0.8964 - val_yolo_layer_2_loss: 1.7616 - val_yolo_layer_3_loss: 2.4251\n",
            "Epoch 13/20\n",
            "160/160 [==============================] - 226s 1s/step - loss: 3.1462 - yolo_layer_1_loss: 0.5264 - yolo_layer_2_loss: 1.0579 - yolo_layer_3_loss: 1.5619 - val_loss: 8.1778 - val_yolo_layer_1_loss: 0.8895 - val_yolo_layer_2_loss: 1.9515 - val_yolo_layer_3_loss: 2.7360\n",
            "Epoch 14/20\n",
            "160/160 [==============================] - 224s 1s/step - loss: 3.0597 - yolo_layer_1_loss: 0.6254 - yolo_layer_2_loss: 1.0755 - yolo_layer_3_loss: 1.3588 - val_loss: 5.6546 - val_yolo_layer_1_loss: 0.8590 - val_yolo_layer_2_loss: 1.5239 - val_yolo_layer_3_loss: 3.2869\n",
            "Epoch 15/20\n",
            "160/160 [==============================] - 233s 1s/step - loss: 2.8834 - yolo_layer_1_loss: 0.5434 - yolo_layer_2_loss: 1.0589 - yolo_layer_3_loss: 1.2810 - val_loss: 9.2959 - val_yolo_layer_1_loss: 1.2479 - val_yolo_layer_2_loss: 1.8248 - val_yolo_layer_3_loss: 2.4651\n",
            "Epoch 16/20\n",
            "160/160 [==============================] - 227s 1s/step - loss: 2.9739 - yolo_layer_1_loss: 0.5776 - yolo_layer_2_loss: 0.9734 - yolo_layer_3_loss: 1.4229 - val_loss: 2.4873 - val_yolo_layer_1_loss: 0.9749 - val_yolo_layer_2_loss: 1.8138 - val_yolo_layer_3_loss: 2.8243\n",
            "Epoch 17/20\n",
            "160/160 [==============================] - 225s 1s/step - loss: 3.0177 - yolo_layer_1_loss: 0.6092 - yolo_layer_2_loss: 1.0278 - yolo_layer_3_loss: 1.3807 - val_loss: 6.4272 - val_yolo_layer_1_loss: 0.6586 - val_yolo_layer_2_loss: 2.0903 - val_yolo_layer_3_loss: 2.4706\n",
            "Epoch 18/20\n",
            "160/160 [==============================] - 219s 1s/step - loss: 3.1336 - yolo_layer_1_loss: 0.4632 - yolo_layer_2_loss: 1.0695 - yolo_layer_3_loss: 1.6010 - val_loss: 1.6157 - val_yolo_layer_1_loss: 0.6999 - val_yolo_layer_2_loss: 1.9087 - val_yolo_layer_3_loss: 2.4278\n",
            "Epoch 19/20\n",
            "160/160 [==============================] - 226s 1s/step - loss: 3.0880 - yolo_layer_1_loss: 0.7021 - yolo_layer_2_loss: 1.0936 - yolo_layer_3_loss: 1.2923 - val_loss: 2.5818 - val_yolo_layer_1_loss: 0.6212 - val_yolo_layer_2_loss: 1.4860 - val_yolo_layer_3_loss: 2.6309\n",
            "Epoch 20/20\n",
            "160/160 [==============================] - 228s 1s/step - loss: 2.8689 - yolo_layer_1_loss: 0.6079 - yolo_layer_2_loss: 0.9535 - yolo_layer_3_loss: 1.3075 - val_loss: 5.7971 - val_yolo_layer_1_loss: 1.3497 - val_yolo_layer_2_loss: 1.5485 - val_yolo_layer_3_loss: 2.5386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2uAZ3VAVe-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-xbuRslVdAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4af3345b-f65c-4dd3-b6c3-88c8d2155d77"
      },
      "source": [
        "trainer.evaluateModel(model_path=\"ring/models\", json_path=\"ring/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n",
            "skipping the evaluation of ring/models/.ipynb_checkpoints since it's not a .h5 file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model File:  ring/models/detection_model-ex-001--loss-0051.698.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.0416\n",
            "mAP: 0.0416\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-002--loss-0012.598.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.1352\n",
            "mAP: 0.1352\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-003--loss-0009.016.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.6186\n",
            "mAP: 0.6186\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-004--loss-0008.259.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.6811\n",
            "mAP: 0.6811\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-005--loss-0007.287.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.6430\n",
            "mAP: 0.6430\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-006--loss-0006.207.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.7150\n",
            "mAP: 0.7150\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-007--loss-0005.684.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.8839\n",
            "mAP: 0.8839\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-010--loss-0004.395.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.8860\n",
            "mAP: 0.8860\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-011--loss-0003.395.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.8891\n",
            "mAP: 0.8891\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-012--loss-0003.011.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.8500\n",
            "mAP: 0.8500\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-015--loss-0002.883.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.8500\n",
            "mAP: 0.8500\n",
            "===============================\n",
            "Model File:  ring/models/detection_model-ex-020--loss-0002.869.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "ring: 0.8500\n",
            "mAP: 0.8500\n",
            "===============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'average_precision': {'ring': 0.04158630992801847},\n",
              "  'map': 0.04158630992801847,\n",
              "  'model_file': 'ring/models/detection_model-ex-001--loss-0051.698.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.13515375950436495},\n",
              "  'map': 0.13515375950436495,\n",
              "  'model_file': 'ring/models/detection_model-ex-002--loss-0012.598.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.6186035022708829},\n",
              "  'map': 0.6186035022708829,\n",
              "  'model_file': 'ring/models/detection_model-ex-003--loss-0009.016.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.6811355421948565},\n",
              "  'map': 0.6811355421948565,\n",
              "  'model_file': 'ring/models/detection_model-ex-004--loss-0008.259.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.6430133742652484},\n",
              "  'map': 0.6430133742652484,\n",
              "  'model_file': 'ring/models/detection_model-ex-005--loss-0007.287.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.71495522995523},\n",
              "  'map': 0.71495522995523,\n",
              "  'model_file': 'ring/models/detection_model-ex-006--loss-0006.207.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.883888888888889},\n",
              "  'map': 0.883888888888889,\n",
              "  'model_file': 'ring/models/detection_model-ex-007--loss-0005.684.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.886},\n",
              "  'map': 0.886,\n",
              "  'model_file': 'ring/models/detection_model-ex-010--loss-0004.395.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.8891304347826087},\n",
              "  'map': 0.8891304347826087,\n",
              "  'model_file': 'ring/models/detection_model-ex-011--loss-0003.395.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.85},\n",
              "  'map': 0.85,\n",
              "  'model_file': 'ring/models/detection_model-ex-012--loss-0003.011.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.85},\n",
              "  'map': 0.85,\n",
              "  'model_file': 'ring/models/detection_model-ex-015--loss-0002.883.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'ring': 0.85},\n",
              "  'map': 0.85,\n",
              "  'model_file': 'ring/models/detection_model-ex-020--loss-0002.869.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUUi2BOSfZhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLMZdFAkfdZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNzlFdcnfhA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector.setModelPath(\"ring/models/detection_model-ex-011--loss-0003.395.h5\") "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1VE79HtfjVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector.setJsonPath(\"ring/json/detection_config.json\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRNxsHOUea9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector.loadModel()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEy7EbOPfpTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detections = detector.detectObjectsFromImage(input_image=\"check.jpg\", output_image_path=\"check-detected.jpg\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEnpmhNAWQ8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74e5cd78-b2a4-4376-f7d2-98214305bd01"
      },
      "source": [
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ring  :  53.84660363197327  :  [297, 438, 485, 544]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cqqX4Zhdrp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "659d41a6-2b7f-4d28-d9e8-aa856f1e3e34"
      },
      "source": [
        "detections = detector.detectObjectsFromImage(input_image=\"check2.jpg\", output_image_path=\"check-detected2.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ring  :  77.93437838554382  :  [263, 307, 516, 578]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FclxZDJzd4yK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecb7e70a-a77f-44f6-d67b-a8c3f3a73379"
      },
      "source": [
        "detections = detector.detectObjectsFromImage(input_image=\"check3.jpg\", output_image_path=\"check-detected3.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ring  :  51.242780685424805  :  [358, 293, 433, 355]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxP8S8btd_-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d00bd20-6264-4180-c13d-0533433a46c7"
      },
      "source": [
        "detections = detector.detectObjectsFromImage(input_image=\"check4.jpg\", output_image_path=\"check-detected4.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ring  :  67.36122965812683  :  [220, 249, 529, 437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Ei8vzSeKE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55ab5e1a-7794-4cd9-8431-a65a0d9c3ca7"
      },
      "source": [
        "#ring on table\n",
        "detections = detector.detectObjectsFromImage(input_image=\"ring7.jpg\", output_image_path=\"ring_check.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ring  :  81.39875531196594  :  [825, 461, 1040, 658]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDMzxPOEe2CR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "109dac58-579f-46d3-fb5b-81fbc4f0ed77"
      },
      "source": [
        "detections = detector.detectObjectsFromImage(input_image=\"ring0.jpg\", output_image_path=\"ring_black.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ring  :  60.06624698638916  :  [2, 102, 232, 232]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWQ3L41yAl7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "14d79a73-35da-4da9-a876-bec2d588549a"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('ring/models/detection_model-ex-017--loss-0003.830.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2baf0499-8b32-4a72-826c-08d41a611e4a\", \"detection_model-ex-017--loss-0003.830.h5\", 246974768)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}